import streamlit as st
from PIL import Image
import json
import os
import yaml
import sys
from typing import Dict, Any, Tuple, List
import pandas as pd
from tqdm import tqdm
import math
import io
from urllib.parse import urlparse

# ä»é¡¹ç›®æ¨¡å—ä¸­å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from encoders import create_encoder, BaseEncoder
from stores import create_vector_store, BaseVectorStore
from reranker import GenerativeAssistant
from prompts import create_prompt_template
from utils import get_config, save_uploaded_file, get_image_from_url_or_path

# Streamlité¡µé¢åŸºç¡€è®¾ç½®
st.set_page_config(layout="wide", page_title="å¤šæ¨¡æ€ RAG é—®ç­”")

# 5. åˆå§‹åŒ–Session State
if 'app_state' not in st.session_state:
    st.session_state['app_state'] = "NEEDS_CONFIG"  # "NEEDS_CONFIG", "NEEDS_INDEX", "READY"
if 'active_tab' not in st.session_state:
    st.session_state['active_tab'] = "é…ç½®"
if 'backend' not in st.session_state:
    st.session_state['backend'] = None
if 'qa_history' not in st.session_state:
    st.session_state['qa_history'] = []
if 'annotation_df' not in st.session_state:
    st.session_state['annotation_df'] = None
if 'annotation_page' not in st.session_state:
    st.session_state['annotation_page'] = 1

# ä¸ºé…ç½®è¡¨å•æ·»åŠ æŒä¹…åŒ–çŠ¶æ€
if 'llm_provider' not in st.session_state:
    st.session_state.llm_provider = "OpenAI API"
if 'openai_api_key' not in st.session_state:
    st.session_state.openai_api_key = ""
if 'openai_base_url' not in st.session_state:
    st.session_state.openai_base_url = ""
if 'azure_api_key' not in st.session_state:
    st.session_state.azure_api_key = ""
if 'azure_endpoint' not in st.session_state:
    st.session_state.azure_endpoint = ""
if 'azure_api_version' not in st.session_state:
    st.session_state.azure_api_version = "2023-12-01-preview"
if 'custom_api_key' not in st.session_state:
    st.session_state.custom_api_key = ""
if 'custom_base_url' not in st.session_state:
    st.session_state.custom_base_url = ""

# 6. å®šä¹‰åç«¯æœåŠ¡å‡½æ•°
@st.cache_data
def load_base_config(config_path="configs/config.yaml") -> Dict[str, Any]:
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

@st.cache_resource
def initialize_backend(_config: Dict[str, Any]) -> Tuple[BaseEncoder, BaseVectorStore, GenerativeAssistant]:
    llm_config = _config.get("llm", {})
    llm_type = llm_config.get("type", "openai")
    
    # æ ¹æ®ç±»å‹è®¾ç½®ç¯å¢ƒå˜é‡
    if llm_type == "azure":
        creds = llm_config.get("azure", {})
        os.environ["AZURE_OPENAI_KEY"] = creds.get("api_key", "")
        os.environ["AZURE_OPENAI_ENDPOINT"] = creds.get("endpoint", "")
    else: # openai or custom
        creds = llm_config.get("openai", {})
        os.environ["OPENAI_API_KEY"] = creds.get("api_key", "")
        if "base_url" in creds and creds["base_url"]:
            os.environ["OPENAI_BASE_URL"] = creds["base_url"]
            
    encoder = create_encoder(_config["encoder"])
    vector_store = create_vector_store(_config["vector_store"])
    assistant = GenerativeAssistant(llm_config)
    return encoder, vector_store, assistant

def perform_indexing(df: pd.DataFrame, vector_store: BaseVectorStore, encoder: BaseEncoder, progress_bar) -> Tuple[bool, str]:
    try:
        items_to_index = df.to_dict('records')
        vector_store.delete_collection()
        
        batch_size = 32
        num_batches = (len(items_to_index) + batch_size - 1) // batch_size
        
        for i in range(num_batches):
            batch_items = items_to_index[i * batch_size : (i + 1) * batch_size]
            
            image_urls = [item['url'] for item in batch_items]
            texts = [item.get('desc', '') for item in batch_items] # æ·»åŠ æ–‡æœ¬æè¿°
            
            # æ‰¹é‡ç¼–ç 
            vectors = [encoder.encode(image=url, text=txt) for url, txt in zip(image_urls, texts)]
            
            # ä½¿ç”¨æ–°çš„æ¥å£
            vector_store.add(vectors=vectors, metadata=batch_items)
            
            progress_bar.progress((i + 1) / num_batches)
            
        vector_store.build_index()
        return True, f"æˆåŠŸä¸º {len(items_to_index)} æ¡æ•°æ®å»ºç«‹äº†ç´¢å¼•ã€‚"
    except Exception as e:
        st.error(f"å»ºç«‹ç´¢å¼•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False, f"å»ºç«‹ç´¢å¼•æ—¶å‘ç”Ÿé”™è¯¯: {e}"

# 7. æ„å»ºä¸»UIç•Œé¢
st.title("ğŸš€ å¤šæ¨¡æ€ RAG é—®ç­”")
tab_titles = ["âš™ï¸ é…ç½®", "ğŸ“š æ•°æ®ç®¡ç†", "ğŸ’¬ å¼€å§‹é—®ç­”"]
tab1, tab2, tab3 = st.tabs(tab_titles)

# 8. å®ç° Tab 1: ç³»ç»Ÿé…ç½®
with tab1:
    st.subheader("ç³»ç»Ÿé…ç½®")
    with st.container(border=True):
        st.info("å½“å‰ç‰ˆæœ¬ä½¿ç”¨å†…ç½®çš„ Faiss ä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œé…ç½®ä¿¡æ¯å·²ä» `config.yaml` åŠ è½½ã€‚")
        vs_type = st.selectbox("å‘é‡æ•°æ®åº“ç±»å‹", ["faiss", "milvus"], disabled=True)
    
    with st.container(border=True):
        st.subheader("LLM é…ç½®")
        st.selectbox(
            "é€‰æ‹©è¯­è¨€æ¨¡å‹æœåŠ¡å•†", 
            ["OpenAI API", "Azure OpenAI", "è‡ªå®šä¹‰ API"],
            key='llm_provider'
        )
        
        if st.session_state.llm_provider == "OpenAI API":
            st.text_input("OpenAI API Key", type="password", key="openai_api_key")
            st.text_input("OpenAI Base URL (å¯é€‰)", placeholder="https://api.openai.com/v1", key="openai_base_url")
        elif st.session_state.llm_provider == "Azure OpenAI":
            st.text_input("Azure OpenAI Key", type="password", key="azure_api_key")
            st.text_input("Azure OpenAI Endpoint", key="azure_endpoint")
            st.text_input("API Version", key="azure_api_version")
        else: # è‡ªå®šä¹‰ API
            st.text_input("API Key", type="password", key="custom_api_key")
            st.text_input("API Base URL", placeholder="ä¾‹å¦‚: https://api.groq.com/openai/v1", key="custom_base_url")

    if st.button("åº”ç”¨é…ç½®", type="primary"):
        # éªŒè¯è¾“å…¥ï¼Œç›´æ¥ä»ä¼šè¯çŠ¶æ€ä¸­è¯»å–å€¼
        valid_input = True
        if st.session_state.llm_provider == "OpenAI API" and not st.session_state.openai_api_key:
            st.error("è¯·è¾“å…¥ OpenAI API Keyã€‚")
            valid_input = False
        elif st.session_state.llm_provider == "Azure OpenAI" and (not st.session_state.azure_api_key or not st.session_state.azure_endpoint):
            st.error("è¯·è¾“å…¥ Azure OpenAI Key å’Œ Endpointã€‚")
            valid_input = False
        elif st.session_state.llm_provider == "è‡ªå®šä¹‰ API" and not st.session_state.custom_base_url:
            st.error("è¯·è¾“å…¥ API Base URLã€‚")
            valid_input = False
        
        if valid_input:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–åç«¯æœåŠ¡..."):
                dynamic_config = load_base_config()
                if st.session_state.llm_provider == "OpenAI API":
                    dynamic_config['llm']['type'] = 'openai'
                    dynamic_config['llm']['openai']['api_key'] = st.session_state.openai_api_key
                    dynamic_config['llm']['openai']['base_url'] = st.session_state.openai_base_url or None
                elif st.session_state.llm_provider == "Azure OpenAI":
                    dynamic_config['llm']['type'] = 'azure'
                    dynamic_config['llm']['azure'] = {
                        'api_key': st.session_state.azure_api_key,
                        'endpoint': st.session_state.azure_endpoint,
                        'api_version': st.session_state.azure_api_version
                    }
                else: # è‡ªå®šä¹‰
                    dynamic_config['llm']['type'] = 'custom'
                    # ä»å·²æœ‰é…ç½®ä¸­è·å–æ¨¡å‹åï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    model_name = dynamic_config.get('llm', {}).get('openai', {}).get('model', 'gpt-3.5-turbo')
                    dynamic_config['llm']['custom'] = {
                        'api_key': st.session_state.custom_api_key,
                        'base_url': st.session_state.custom_base_url,
                        'model': model_name
                    }

                st.session_state.backend = initialize_backend(dynamic_config)
                st.session_state.app_state = "NEEDS_INDEX"
                st.success("âœ… é…ç½®æˆåŠŸï¼è¯·å‰å¾€â€œæ•°æ®ç®¡ç†â€é€‰é¡¹å¡ä¸Šä¼ æ•°æ®å¹¶å»ºç«‹ç´¢å¼•ã€‚")

# 9. å®ç° Tab 2: æ•°æ®ç®¡ç†
with tab2:
    if st.session_state.app_state == "NEEDS_CONFIG":
        st.warning("âš ï¸ è¯·å…ˆåœ¨â€œé…ç½®â€é€‰é¡¹å¡ä¸­å®Œæˆç³»ç»Ÿé…ç½®ã€‚")
    else:
        st.subheader("æ•°æ®ä¸Šä¼ ä¸ç´¢å¼•")
        left, right = st.columns([1, 1])
        with left:
            with st.container(border=True):
                st.markdown("##### 1. ä¸Šä¼ æ•°æ®æ–‡ä»¶")
                with open("dataset/template.xlsx", "rb") as f:
                    st.download_button(
                        label="ä¸‹è½½æ•°æ®æ¨¡æ¿",
                        data=f,
                        file_name="template.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )
                uploaded_file = st.file_uploader(
                    "æ”¯æŒ .csv å’Œ .xlsx æ ¼å¼", 
                    type=["csv", "xlsx"], 
                    key="file_uploader"
                )
                if uploaded_file:
                    try:
                        if uploaded_file.name.endswith('.csv'):
                            st.session_state.annotation_df = pd.read_csv(uploaded_file)
                        else:
                            st.session_state.annotation_df = pd.read_excel(uploaded_file)
                        st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        with right:
            with st.container(border=True):
                st.markdown("##### 2. å»ºç«‹ç´¢å¼•")
                if st.session_state.annotation_df is not None:
                    st.metric("å¾…ç´¢å¼•æ•°æ®é‡", f"{len(st.session_state.annotation_df)} æ¡")
                    if st.button("å¼€å§‹å»ºç«‹ç´¢å¼•", type="primary"):
                        encoder, vector_store, _ = st.session_state.backend
                        progress_bar = st.progress(0, "æ­£åœ¨å»ºç«‹ç´¢å¼•...")
                        success, message = perform_indexing(st.session_state.annotation_df, vector_store, encoder, progress_bar)
                        if success:
                            st.session_state.app_state = "READY"
                            st.success(f"âœ… {message} ç°åœ¨å¯ä»¥å»â€œå¼€å§‹é—®ç­”â€å•¦ï¼")
                            progress_bar.progress(1.0, "ç´¢å¼•å®Œæˆï¼")
                        else:
                            st.error(f"ç´¢å¼•å¤±è´¥: {message}")
                else:
                    st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ã€‚")
        
        st.divider()

        st.subheader("åœ¨çº¿æ•°æ®æ ‡æ³¨å¹³å°")
        if st.session_state.annotation_df is not None:
            # åˆ›å»ºä¸€ä¸ªå·¥ä½œå‰¯æœ¬
            df = st.session_state.annotation_df.copy()

            # --- 1. æ ‡æ³¨çŠ¶æ€åˆ†æ ---
            # ç¡®ä¿åˆ—å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å¡«å……ä¸ºç©ºå­—ç¬¦ä¸²
            if 'desc' not in df.columns:
                df['desc'] = ''
            if 'category' not in df.columns:
                df['category'] = ''

            # å¡«å……NaNå€¼ä»¥ä¾¿ç»Ÿä¸€å¤„ç†
            df['desc'] = df['desc'].fillna('')
            df['category'] = df['category'].fillna('')

            # åˆ¤æ–­æ˜¯å¦å·²æ ‡æ³¨ (æè¿°å’Œç±»åˆ«éƒ½ä¸ä¸ºç©º)
            df['is_annotated'] = (df['desc'].str.strip() != '') & (df['category'].str.strip() != '')
            
            total_items = len(df)
            annotated_count = df['is_annotated'].sum()
            unannotated_count = total_items - annotated_count

            # --- 2. UI - çŠ¶æ€æŒ‡æ ‡ä¸ç­›é€‰ ---
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("æ€»æ•°æ®é‡", f"{total_items} æ¡")
            with c2:
                st.metric("å·²æ ‡æ³¨", f"{annotated_count} æ¡")
            with c3:
                st.metric("å¾…æ ‡æ³¨", f"{unannotated_count} æ¡")
            
            if unannotated_count == 0:
                st.success("ğŸ‰ æ­å–œï¼æ‰€æœ‰æ•°æ®éƒ½å·²æ ‡æ³¨å®Œæˆã€‚")

            with st.container(border=True):
                st.markdown("##### ç­›é€‰ä¸è§†å›¾")
                filter_c1, filter_c2 = st.columns([3, 1])
                
                # æŒ‰ç±»åˆ«ç­›é€‰
                all_categories = sorted([cat for cat in df['category'].unique() if cat])
                selected_categories = filter_c1.multiselect(
                    "æŒ‰ç±»åˆ«ç­›é€‰",
                    options=all_categories,
                    help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªç±»åˆ«ä»¥ç­›é€‰æ•°æ®ã€‚"
                )
                
                # ä»…æ˜¾ç¤ºå¾…æ ‡æ³¨æ•°æ®çš„å¤é€‰æ¡†
                show_only_unannotated = filter_c2.checkbox(
                    "ä»…æ˜¾ç¤ºå¾…æ ‡æ³¨", 
                    value=(unannotated_count > 0), # å¦‚æœæœ‰æœªæ ‡æ³¨é¡¹ï¼Œé»˜è®¤å‹¾é€‰
                    help="å‹¾é€‰æ­¤é¡¹ä»¥æŸ¥çœ‹æ‰€æœ‰ç¼ºå°‘æè¿°æˆ–ç±»åˆ«çš„æ•°æ®ã€‚"
                )

            # --- 3. åº”ç”¨ç­›é€‰é€»è¾‘ ---
            df_to_display = df

            if show_only_unannotated:
                df_to_display = df_to_display[~df_to_display['is_annotated']]
            
            if selected_categories:
                df_to_display = df_to_display[df_to_display['category'].isin(selected_categories)]

            st.markdown(f"**æŸ¥è¯¢ç»“æœ: {len(df_to_display)} æ¡**")

            # --- 4. åˆ†é¡µä¸è¡¨å•å±•ç¤º ---
            if not df_to_display.empty:
                items_per_page = 5
                total_pages = math.ceil(len(df_to_display) / items_per_page)
                
                # å¦‚æœç­›é€‰åå½“å‰é¡µç è¶…å‡ºèŒƒå›´ï¼Œé‡ç½®ä¸ºç¬¬ä¸€é¡µ
                if st.session_state.annotation_page > total_pages:
                    st.session_state.annotation_page = 1
                
                page_number = st.number_input('é¡µç ', min_value=1, max_value=total_pages, value=st.session_state.annotation_page)
                st.session_state.annotation_page = page_number
                
                start_idx = (page_number - 1) * items_per_page
                end_idx = start_idx + items_per_page
                
                for index, row in df_to_display.iloc[start_idx:end_idx].iterrows():
                    with st.container(border=True):
                        c1, c2 = st.columns([1, 2])
                        with c1:
                            st.image(row['url'], use_container_width=True, caption=f"ID: {index}")
                        with c2:
                            with st.form(f"form_{index}"):
                                new_desc = st.text_area("æè¿° (desc)", value=row.get('desc', ''), height=150)
                                new_cat = st.text_input("ç±»åˆ« (category)", value=row.get('category', ''))
                                if st.form_submit_button("ä¿å­˜æ›´æ”¹"):
                                    # ç›´æ¥åœ¨åŸå§‹DataFrameä¸Šä¿®æ”¹
                                    st.session_state.annotation_df.at[index, 'desc'] = new_desc
                                    st.session_state.annotation_df.at[index, 'category'] = new_cat
                                    st.toast(f"ID {index} å·²æ›´æ–°ï¼")
                                    # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢å’Œç»Ÿè®¡æ•°æ®
                                    st.rerun()
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®ã€‚")
        else:
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹æ ‡æ³¨ã€‚")

# 10. å®ç° Tab 3: å¼€å§‹é—®ç­”
with tab3:
    if st.session_state.app_state != "READY":
        st.warning("âš ï¸ ç³»ç»Ÿå°šæœªå°±ç»ªã€‚è¯·å…ˆå®Œæˆé…ç½®å¹¶å»ºç«‹æ•°æ®ç´¢å¼•ã€‚")
    else:
        for msg in st.session_state.qa_history:
            with st.chat_message(msg["role"]):
                if msg.get("image_query"):
                    st.image(msg["image_query"], width=150)
                if msg.get("text_query"):
                    st.write(msg["text_query"])
                
                # æ–°çš„ç­”æ¡ˆæ˜¾ç¤ºé€»è¾‘
                if "answer" in msg:
                    st.markdown(msg["answer"])
                    
                    # å¦‚æœæœ‰æŒ‡å®šçš„æ¨èå›¾ç‰‡ï¼Œåˆ™ç›´æ¥å±•ç¤º
                    if msg.get("recommended_item"):
                        st.image(
                            msg["recommended_item"]["url"], 
                            caption=f"ä¸ºæ‚¨æ¨è: {msg['recommended_item'].get('desc', '')[:50]}",
                            use_container_width=True
                        )

                    # å°†æ‰€æœ‰å‚è€ƒå›¾ç‰‡æ”¾å…¥æŠ˜å é¢æ¿ä¸­
                    if msg.get("references"):
                        with st.expander("æŸ¥çœ‹æ‰€æœ‰å‚è€ƒå›¾ç‰‡"):
                            cols = st.columns(len(msg["references"]))
                            for i, ref in enumerate(msg["references"]):
                                with cols[i]:
                                    st.image(ref['url'], caption=ref.get('desc', '')[:50], use_container_width=True)

        query_image_upload = st.file_uploader("ä¸Šä¼ æŸ¥è¯¢å›¾ç‰‡", type=["jpg", "png", "jpeg"])
        query_text_input = st.text_area("è¾“å…¥ä½ çš„é—®é¢˜")
        
        if st.button("å‘é€é—®é¢˜", type="primary"):
            if not query_image_upload and not query_text_input.strip():
                st.error("è¯·è¾“å…¥é—®é¢˜æˆ–ä¸Šä¼ å›¾ç‰‡ã€‚")
            else:
                user_message = {"role": "user"}
                query_image_bytes = None
                if query_image_upload:
                    query_image_bytes = query_image_upload.getvalue()
                    user_message["image_query"] = query_image_bytes
                if query_text_input.strip():
                    user_message["text_query"] = query_text_input
                
                st.session_state.qa_history.append(user_message)
                st.rerun()

    if st.session_state.qa_history and st.session_state.qa_history[-1]["role"] == "user":
        last_user_msg = st.session_state.qa_history[-1]
        
        query_image_path = None
        if last_user_msg.get("image_query"):
            # å°†ä¸Šä¼ çš„å›¾ç‰‡å­—èŠ‚ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ä»¥ä¼ é€’ç»™æ¨¡å‹
            with open("temp_query_image.jpg", "wb") as f:
                f.write(last_user_msg["image_query"])
            query_image_path = "temp_query_image.jpg"

        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                encoder, vector_store, assistant = st.session_state.backend
                
                # ç¼–ç 
                query_vector = encoder.encode(image=query_image_path, text=last_user_msg.get("text_query"))
                
                # æ£€ç´¢
                candidates = vector_store.search(vector=query_vector, top_k=5)
                
                # ç”Ÿæˆ (ç°åœ¨è¿”å›ä¸‰å…ƒç»„)
                answer_text, recommended_idx, references = assistant.answer(
                    instruction=last_user_msg.get("text_query", "è¯·æè¿°è¿™å¼ å›¾ç‰‡ï¼Œå¹¶æ‰¾åˆ°ç›¸ä¼¼çš„å•†å“ã€‚"),
                    candidates=candidates,
                    query_image=query_image_path,
                    query_text=last_user_msg.get("text_query")
                )
                
                # å‡†å¤‡è¦å­˜å…¥å†å²è®°å½•çš„æ¶ˆæ¯ä½“
                assistant_message = {
                    "role": "assistant", 
                    "answer": answer_text,
                    "references": references,
                    "recommended_item": references[recommended_idx] if recommended_idx is not None else None
                }
                st.session_state.qa_history.append(assistant_message)
                st.rerun()
